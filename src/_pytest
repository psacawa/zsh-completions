#compdef pytest

# AUTOMATCALLY GENERATED by `shtab`

_shtab_pytest_options_=(
  "--print-completion[print shell completion script]:print_completion:(bash zsh)"
  "-k[only run tests which match the given substring expression. An expression is a python evaluatable expression where all names are substring-matched against test names and their parent classes. Example\: -k \'test_method or test_other\' matches all test functions and classes whose name contains \'test_method\' or \'test_other\', while -k \'not test_method\' matches those that don\'t contain \'test_method\' in their names. -k \'not test_method and not test_other\' will eliminate the matches. Additionally keywords are matched to classes and functions containing extra names in their \'extra_keyword_matches\' set, as well as functions which have names assigned directly to them. The matching is case-insensitive.]:keyword:"
  "-m[only run tests matching given mark expression.
For example\: -m \'mark1 and not mark2\'.]:markexpr:"
  "--markers[show markers (builtin, plugin and per-project ones).]"
  {-x,--exitfirst}"[exit instantly on first error or failed test.]"
  {--fixtures,--funcargs}"[show available fixtures, sorted by plugin appearance (fixtures with leading \'_\' are only shown with \'-v\')]"
  "--fixtures-per-test[show fixtures per test]"
  "--pdb[start the interactive Python debugger on errors or KeyboardInterrupt.]"
  "--pdbcls[specify a custom interactive Python debugger for use with --pdb.For example\: --pdbcls\=IPython.terminal.debugger\:TerminalPdb]:usepdb_cls:"
  "--trace[Immediately break when running each test.]"
  "--capture[per-test capturing method\: one of fd\|sys\|no\|tee-sys.]:capture:(fd sys no tee-sys)"
  "-s[shortcut for --capture\=no.]"
  "--runxfail[report the results of xfail tests as if they were not marked]"
  {--lf,--last-failed}"[rerun only the tests that failed at the last run (or all if none failed)]"
  {--ff,--failed-first}"[run all tests, but run the last failures first.
This may re-order tests and thus lead to repeated fixture setup\/teardown.]"
  {--nf,--new-first}"[run tests from new files first, then the rest of the tests sorted by file mtime]"
  "*--cache-show[show cache contents, don\'t perform collection or tests. Optional argument\: glob (default\: \'\*\').]:cacheshow:"
  "--cache-clear[remove all cache contents at start of test run.]"
  {--lfnf,--last-failed-no-failures}"[which tests to run with no previously (known) failures.]:last_failed_no_failures:(all none)"
  {--sw,--stepwise}"[exit on test failure and continue from last failing test next time]"
  {--sw-skip,--stepwise-skip}"[ignore the first failing test but stop on the next failing test]"
  "--durations[show N slowest setup\/test durations (N\=0 for all).]:durations:"
  "--durations-min[Minimal duration in seconds for inclusion in slowest list. Default 0.005]:durations_min:"
  "*"{-v,--verbose}"[increase verbosity.]"
  "--no-header[disable header]"
  "--no-summary[disable summary]"
  {-q,--quiet}"[decrease verbosity.]:verbose:"
  "--verbosity[set verbosity. Default is 0.]:verbose:"
  "-r[show extra test summary info as specified by chars\: (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed, (p)assed, (P)assed with output, (a)ll except passed (p\/P), or (A)ll. (w)arnings are enabled by default (see --disable-warnings), \'N\' can be used to reset the list. (default\: \'fE\').]:reportchars:"
  {--disable-warnings,--disable-pytest-warnings}"[disable warnings summary]"
  {-l,--showlocals}"[show locals in tracebacks (disabled by default).]"
  "--tb[traceback print mode (auto\/long\/short\/line\/native\/no).]:tbstyle:(auto long short no line native)"
  "--show-capture[Controls how captured stdout\/stderr\/log is shown on failed tests. Default is \'all\'.]:showcapture:(no stdout stderr log all)"
  {--fulltrace,--full-trace}"[don\'t cut any tracebacks (default is to cut).]"
  "--color[color terminal output (yes\/no\/auto).]:color:(yes no auto)"
  "--code-highlight[Whether code should be highlighted (only if --color is also enabled)]:code_highlight:(yes no)"
  "--pastebin[send failed\|all info to bpaste.net pastebin service.]:pastebin:(failed all)"
  {--junitxml,--junit-xml}"[create junit-xml style report file at given path.]:xmlpath:"
  {--junitprefix,--junit-prefix}"[prepend prefix to classnames in junit-xml output]:junitprefix:"
  "*"{-W,--pythonwarnings}"[set which warnings to report, see -W option of python itself.]:pythonwarnings:"
  "--maxfail[exit after first num failures or errors.]:maxfail:"
  "--strict-config[any warnings encountered while parsing the \`pytest\` section of the configuration file raise errors.]"
  "--strict-markers[markers not registered in the \`markers\` section of the configuration file raise errors.]"
  "--strict[(deprecated) alias to --strict-markers.]"
  "-c[load configuration from \`file\` instead of trying to locate one of the implicit configuration files.]:inifilename:"
  "--continue-on-collection-errors[Force test execution even if collection errors occur.]"
  "--rootdir[Define root directory for tests. Can be relative path\: \'root_dir\', \'.\/root_dir\', \'root_dir\/another_dir\/\'\; absolute path\: \'\/home\/user\/root_dir\'\; path with variables\: \'\$HOME\/root_dir\'.]:rootdir:"
  {--collectonly,--collect-only,--co}"[only collect tests, don\'t execute them.]"
  "--pyargs[try to interpret all arguments as python packages.]"
  "*--ignore[ignore path during collection (multi-allowed).]:ignore:"
  "*--ignore-glob[ignore path pattern during collection (multi-allowed).]:ignore_glob:"
  "*--deselect[deselect item (via node id prefix) during collection (multi-allowed).]:deselect:"
  "--confcutdir[only load conftest.py\'s relative to specified dir.]:confcutdir:"
  "--noconftest[Don\'t load any conftest.py files.]"
  {--keepduplicates,--keep-duplicates}"[Keep duplicate tests.]"
  "--collect-in-virtualenv[Don\'t ignore tests in a local virtualenv directory]"
  "--import-mode[prepend\/append to sys.path when importing test modules and conftest files, default is to prepend.]:importmode:(prepend append importlib)"
  "--doctest-modules[run doctests in all .py modules]"
  "--doctest-report[choose another output format for diffs on doctest failure]:doctestreport:(none cdiff ndiff udiff only_first_failure)"
  "*--doctest-glob[doctests file matching pattern, default\: test\*.txt]:doctestglob:"
  "--doctest-ignore-import-errors[ignore doctest ImportErrors]"
  "--doctest-continue-on-failure[for a given doctest, continue to run after the first failure]"
  "--basetemp[base temporary directory for this test run.(warning\: this directory is removed if it exists)]:basetemp:"
  "*"{-V,--version}"[display pytest version and information about plugins. When given twice, also display information about plugins.]"
  {-h,--help}"[show help message and configuration info]:help:"
  "*-p[early-load given plugin module name or entry point (multi-allowed).
To avoid loading of plugins, use the \`no\:\` prefix, e.g. \`no\:doctest\`.]:plugins:"
  {--traceconfig,--trace-config}"[trace considerations of conftest.py files.]"
  "--debug[store internal tracing debug information in this log file.
This file is opened with \'w\' and truncated as a result, care advised.
Defaults to \'pytestdebug.log\'.]:debug:"
  "*"{-o,--override-ini}"[override ini option with \"option\=value\" style, e.g. \`-o xfail_strict\=True -o cache_dir\=cache\`.]:override_ini:"
  "--assert[Control assertion debugging tools.
\'plain\' performs no assertion debugging.
\'rewrite\' (the default) rewrites assert statements in test modules on import to provide assert expression information.]:assertmode:(rewrite plain)"
  {--setuponly,--setup-only}"[only setup fixtures, do not execute tests.]"
  {--setupshow,--setup-show}"[show setup of fixtures while executing tests.]"
  {--setupplan,--setup-plan}"[show what fixtures and tests would be executed but don\'t execute anything.]"
  "--log-level[level of messages to catch\/display.
Not set by default, so it depends on the root\/parent log handler\'s effective level, where it is \"WARNING\" by default.]:log_level:"
  "--log-format[log format as used by the logging module.]:log_format:"
  "--log-date-format[log date format as used by the logging module.]:log_date_format:"
  "--log-cli-level[cli logging level.]:log_cli_level:"
  "--log-cli-format[log format as used by the logging module.]:log_cli_format:"
  "--log-cli-date-format[log date format as used by the logging module.]:log_cli_date_format:"
  "--log-file[path to a file when logging will be written to.]:log_file:"
  "--log-file-level[log file logging level.]:log_file_level:"
  "--log-file-format[log format as used by the logging module.]:log_file_format:"
  "--log-file-date-format[log date format as used by the logging module.]:log_file_date_format:"
  "--log-auto-indent[Auto-indent multiline messages passed to the logging module. Accepts true\|on, false\|off or an integer.]:log_auto_indent:" 
  "--reuse-db [Re-use the testing database if it already exists, ]::" 
  "--create-db [Re-create the database, even if it exists. This ]::" 
  "--ds [Set DJANGO_SETTINGS_MODULE.]::" 
  "--dc [Set DJANGO_CONFIGURATION.]::" 
  "--no-migrations [Disable Django migrations on test setup]::" 
  "--migrations [Enable Django migrations on test setup]::" 
  "--liveserver [Address and port for the live_server fixture.]::" 
  "--fail-on-template-vars [Fail for invalid variables in templates.]::" 
)

_shtab_pytest_commands_() {
  local _commands=(
    
  )

  _describe 'pytest commands' _commands
}


typeset -A opt_args
local context state line curcontext="$curcontext"

_arguments \
  $_shtab_pytest_options_ \
  "(*)::file_or_dir:" \
  ': :_shtab_pytest_commands_' \
  '*::args:->args'

case $words[1] in
  
esac
